{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64f7a57-7c7e-4f14-ab77-442e306a26fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 691.5ms\n",
      "Speed: 17.6ms preprocess, 691.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 541.8ms\n",
      "Speed: 20.7ms preprocess, 541.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 453.5ms\n",
      "Speed: 13.6ms preprocess, 453.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 444.8ms\n",
      "Speed: 12.5ms preprocess, 444.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 443.4ms\n",
      "Speed: 14.0ms preprocess, 443.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 476.1ms\n",
      "Speed: 13.6ms preprocess, 476.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 560.7ms\n",
      "Speed: 18.1ms preprocess, 560.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 510.0ms\n",
      "Speed: 17.1ms preprocess, 510.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 443.5ms\n",
      "Speed: 14.0ms preprocess, 443.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 447.4ms\n",
      "Speed: 13.8ms preprocess, 447.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 vehicles, 328.2ms\n",
      "Speed: 14.0ms preprocess, 328.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 259.6ms\n",
      "Speed: 8.1ms preprocess, 259.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 258.2ms\n",
      "Speed: 9.6ms preprocess, 258.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 259.7ms\n",
      "Speed: 8.5ms preprocess, 259.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.7ms\n",
      "Speed: 9.5ms preprocess, 278.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 275.5ms\n",
      "Speed: 8.0ms preprocess, 275.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 262.1ms\n",
      "Speed: 10.0ms preprocess, 262.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 vehicles, 262.3ms\n",
      "Speed: 12.6ms preprocess, 262.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 256.7ms\n",
      "Speed: 9.0ms preprocess, 256.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 255.5ms\n",
      "Speed: 8.5ms preprocess, 255.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vehicle, 258.8ms\n",
      "Speed: 9.3ms preprocess, 258.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.2ms\n",
      "Speed: 9.5ms preprocess, 264.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 255.9ms\n",
      "Speed: 9.2ms preprocess, 255.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 261.1ms\n",
      "Speed: 7.5ms preprocess, 261.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 262.2ms\n",
      "Speed: 9.6ms preprocess, 262.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 266.1ms\n",
      "Speed: 9.5ms preprocess, 266.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 272.4ms\n",
      "Speed: 9.5ms preprocess, 272.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 260.4ms\n",
      "Speed: 8.5ms preprocess, 260.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 259.8ms\n",
      "Speed: 9.0ms preprocess, 259.8ms inference, 0.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 260.0ms\n",
      "Speed: 8.5ms preprocess, 260.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import carla\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Trained models\n",
    "#YOLO_PATH = 'weights/best_n.pt'\n",
    "YOLO_PATH = 'weights/best_s.pt'\n",
    "\n",
    "#yolo Pretrained models\n",
    "#YOLO_PATH = 'weights/yolov8n.pt'\n",
    "#YOLO_PATH = 'weights/yolov8s.pt'\n",
    "\n",
    "#The local Host for carla simulator is 2000\n",
    "client = carla.Client('localhost', 2000)\n",
    "# world has methods to access all things in simulator(vehicles, buildings, etc and spawning)\n",
    "client.set_timeout(20.0)\n",
    "world = client.get_world() \n",
    "\n",
    "#blueprint will acess to all bps to create objects( like vehicles, people)\n",
    "bp_lib = world.get_blueprint_library()\n",
    "#spawn points to spawn\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "#From vehicle blueprint getting the information of specific vehicle\n",
    "vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "#Shifting the view to the spectator of the car(camera)\n",
    "spectator = world.get_spectator()\n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x = -4, z = 2.5)), vehicle.get_transform().rotation)\n",
    "spectator.set_transform(transform)\n",
    "\n",
    "#Spawning the Vehicles as npc\n",
    "spawn_num = 30\n",
    "for i in range(spawn_num):\n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle'))\n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "    \n",
    "#autopiloting the vehicles\n",
    "for v in world.get_actors().filter('*vehicle*'):\n",
    "    v.set_autopilot(True)\n",
    "    \n",
    "#Attaching camera sensor to the vehicle\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "\n",
    "#Setting the width and height to display\n",
    "IM_WIDTH =  256*4\n",
    "IM_HEIGHT =  256*3\n",
    "\n",
    "camera_bp.set_attribute('image_size_x', f'{IM_WIDTH}')\n",
    "camera_bp.set_attribute('image_size_y', f'{IM_HEIGHT}')\n",
    "camera_bp.set_attribute('fov', '110')\n",
    "\n",
    "#transforming the carla into a desirable position and attaching to the vehicle\n",
    "camera_init_trans = carla.Transform(carla.Location(x = 1.5, z = 1.6 ))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to = vehicle)\n",
    "\n",
    "#To save images in the drive\n",
    "#camera.listen(lambda image: image.save_to_disk('out/%06d.png' % image.frame))\n",
    "\n",
    "#To stop saving the images\n",
    "#camera.stop()\n",
    "\n",
    "#converting the image to use yolo\n",
    "def camera_callback(image, data_dict):\n",
    "    #data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    image_data = np.array(image.raw_data)\n",
    "    image_rgb = image_data.reshape((image.height, image.width, 4))[:, :, :3]  # Extract RGB channels\n",
    "    data_dict['image'] = image_rgb\n",
    "\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "\n",
    "camera.listen(lambda image:camera_callback(image, camera_data))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "img = camera_data['image']\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#use the best model for object detection\n",
    "\n",
    "#model = YOLO('yolov8n.pt')\n",
    "model = YOLO(YOLO_PATH)\n",
    "\n",
    "class_name = ['bike', 'vehicle']\n",
    "\n",
    "while True:\n",
    "    frame = camera_data['image']\n",
    "    results = model(frame ,show = False) \n",
    "    bbox_xyxy = []\n",
    "    confs = []\n",
    "    clss = []\n",
    "    \n",
    "    for box in results:  \n",
    "        for r in box.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, conf, id = r\n",
    "            bbox_xyxy.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "            confs.append(conf)\n",
    "            clss.append(int(id))\n",
    "            \n",
    "    frame = cv2.UMat(frame)\n",
    "    for bbox, cls, conf in zip(bbox_xyxy, clss, confs):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        color = (0, 255, 0)  # Green color for bounding boxes\n",
    "        label = f'{class_name[cls]}: {conf:.2f}'\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    cv2.imshow(\"YOLOv8\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "camera.stop()\n",
    "camera.destroy()\n",
    "vehicle.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85836a3-4cf1-4e02-948d-2e343e2bfae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
